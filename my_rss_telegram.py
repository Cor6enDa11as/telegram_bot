#!/usr/bin/env python3
import os
import feedparser
import requests
from flask import Flask
from threading import Thread
import time
import logging
from dotenv import load_dotenv
import re
from urllib.parse import urlparse

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

load_dotenv()
app = Flask(__name__)

BOT_TOKEN = os.getenv('BOT_TOKEN')
CHANNEL_ID = os.getenv('CHANNEL_ID')
RSS_FEED_URLS = [url.strip() for url in os.getenv('RSS_FEED_URLS', '').split(',') if url.strip()]

if not all([BOT_TOKEN, CHANNEL_ID, RSS_FEED_URLS]):
    logger.error("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
    exit(1)

last_links = {}

def extract_clean_text(html):
    if not html:
        return ""
    clean = re.sub(r'<[^>]+>', ' ', html)
    clean = re.sub(r'\s+', ' ', clean).strip()
    return clean[:300] + "‚Ä¶" if len(clean) > 300 else clean

def fetch_rss_with_browser_headers(rss_url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9,ru;q=0.8',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Cache-Control': 'max-age=0'
    }
    response = requests.get(rss_url, headers=headers, timeout=20)
    response.raise_for_status()
    return feedparser.parse(response.content)

def robust_parse_feed(rss_url):
    methods = [
        lambda: fetch_rss_with_browser_headers(rss_url),
        lambda: feedparser.parse(rss_url),
    ]
    for method in methods:
        try:
            feed = method()
            if feed and hasattr(feed, 'entries') and len(feed.entries) > 0:
                entry = feed.entries[0]
                if entry.get('link') or entry.get('title'):
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {urlparse(rss_url).netloc}")
                    return feed
        except Exception as e:
            logger.debug(f"–ú–µ—Ç–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è {rss_url}: {e}")
            continue
    logger.error(f"‚ùå –í—Å–µ –º–µ—Ç–æ–¥—ã –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å: {rss_url}")
    return None

def create_telegraph_page(title, summary, source_url, image_url=None):
    """–°–æ–∑–¥–∞—ë—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –Ω–∞ telegra.ph –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Å—ã–ª–∫—É"""
    content = []
    if image_url:
        content.append({"tag": "img", "attrs": {"src": image_url}})
    content.append({"tag": "p", "children": [summary]})
    content.append({
        "tag": "p",
        "children": [
            {"tag": "em", "children": ["–ò—Å—Ç–æ—á–Ω–∏–∫: "]},
            {"tag": "a", "attrs": {"href": source_url}, "children": [source_url]}
        ]
    })
    payload = {
        "title": title,
        "author_name": "RSS Bot",
        "content": content,
        "return_content": False
    }
    try:
        resp = requests.post("https://api.telegra.ph/createPage", json=payload, timeout=10)
        if resp.ok:
            data = resp.json()
            if data.get("ok"):
                return data["result"]["url"]
    except Exception as e:
        logger.error(f"‚ùå Telegraph –æ—à–∏–±–∫–∞: {e}")
    return None

def send_via_telegraph(entry, rss_url):
    title = entry.get('title', '–ù–æ–≤–æ—Å—Ç—å').strip()
    summary = extract_clean_text(entry.get('summary', entry.get('description', '')))
    source_url = entry.link

    # –ö–∞—Ä—Ç–∏–Ω–∫–∏ –ø–æ –¥–æ–º–µ–Ω—É
    cover_map = {
        'opennet': 'https://i.imgur.com/5XJmVQl.png',
        '4pda': 'https://i.imgur.com/rKzB0yP.png',
        'gsmarena': 'https://i.imgur.com/9WzFQ4a.png',
    }
    domain = urlparse(rss_url).netloc.replace('www.', '').split('.')[0].lower()
    image_url = cover_map.get(domain)

    telegraph_url = create_telegraph_page(title, summary, source_url, image_url)
    if not telegraph_url:
        return False

    hashtag = "#" + re.sub(r'[^a-zA-Z0-9–∞-—è–ê-–Ø—ë–Å]', '', domain)
    message = f"{telegraph_url}\n\n{hashtag}"

    try:
        resp = requests.post(
            f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
            json={'chat_id': CHANNEL_ID, 'text': message, 'disable_web_page_preview': False},
            timeout=10
        )
        return resp.ok
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
        return False

def rss_check_loop():
    global last_links

    logger.info("üöÄ –ó–∞–ø—É—Å–∫ RSS –±–æ—Ç–∞ (Telegraph mode)")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    for url in RSS_FEED_URLS:
        try:
            feed = robust_parse_feed(url)
            if feed and feed.entries:
                last_links[url] = feed.entries[0].link
                logger.info(f"‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {urlparse(url).netloc}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ {url}: {e}")

    time.sleep(60)

    while True:
        try:
            for url in RSS_FEED_URLS:
                try:
                    feed = robust_parse_feed(url)
                    if not feed or not feed.entries:
                        continue

                    latest = feed.entries[0]
                    link = latest.link

                    if last_links.get(url) != link:
                        logger.info(f"üéâ –ù–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å: {urlparse(url).netloc}")
                        if send_via_telegraph(latest, url):
                            last_links[url] = link
                            time.sleep(5)
                        else:
                            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤–æ—Å—Ç—å –∏–∑ {url}")

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {url}: {e}")

            logger.info("‚úÖ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à—ë–Ω")
            time.sleep(900)

        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            time.sleep(60)

@app.route('/')
def home():
    return 'RSS Bot + Telegraph is running!'

if __name__ == '__main__':
    logger.info(f"üì° –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è {len(RSS_FEED_URLS)} –ª–µ–Ω—Ç")
    Thread(target=rss_check_loop, daemon=True).start()
    app.run(host='0.0.0.0', port=int(os.getenv('PORT', 5000)))
