#!/usr/bin/env python3
import feedparser
import time
import requests
import re
import html
from datetime import datetime
import os
from flask import Flask
import threading
from urllib.parse import urlparse

app = Flask(__name__)

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHANNEL_ID = os.getenv('TELEGRAM_CHANNEL_ID')

if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHANNEL_ID:
    print("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã TELEGRAM_BOT_TOKEN –∏–ª–∏ TELEGRAM_CHANNEL_ID")
    exit(1)

RSS_SOURCES = [
    {"url": "https://habr.com/ru/rss/hubs/linux_dev/articles/?fl=ru", "hashtag": "#linux"},
    {"url": "https://habr.com/ru/rss/hubs/linux/articles/?fl=ru", "hashtag": "#linux"},
    {"url": "https://habr.com/ru/rss/hubs/popular_science/articles/?fl=ru", "hashtag": "#–Ω–∞—É–∫–∞"},
    {"url": "https://habr.com/ru/rss/hubs/astronomy/articles/?fl=ru", "hashtag": "#–∞—Å—Ç—Ä–æ–Ω–æ–º–∏—è"},
    {"url": "https://habr.com/ru/rss/flows/popsci/articles/?fl=ru", "hashtag": "#–Ω–∞—É–∫–∞"},
    {"url": "https://4pda.to/feed/", "hashtag": "#–º–æ–±–∏–ª—å–Ω—ã–µ"},
    {"url": "https://tech.onliner.by/feed", "hashtag": "#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"},
    {"url": "https://www.ixbt.com/export/news.rss", "hashtag": "#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏#–≥–∞–¥–∂–µ—Ç—ã#—Ç–µ—Ö–Ω–∏–∫–∞#–∞–≤—Ç–æ"},
    {"url": "https://androidinsider.ru/feed", "hashtag": "#android"},
    {"url": "https://naked-science.ru/feed", "hashtag": "#–Ω–∞—É–∫–∞"},
    {"url": "https://www.opennet.ru/opennews/opennews_full_utf.rss", "hashtag": "#linux"},
    {"url": "https://www.comss.ru/linux.php", "hashtag": "#linux"},
    {"url": "https://www.linux.org.ru/section-rss.jsp?section=1", "hashtag": "#linux"},
    {"url": "https://www.phoronix.com/rss.php", "hashtag": "#linux"},
    {"url": "https://linuxiac.com/feed/", "hashtag": "#linux"},
    {"url": "https://www.linuxinsider.com/rss-feed", "hashtag": "#linux"},
    {"url": "https://distrowatch.com/news/dw.xml", "hashtag": "#linux"},
    {"url": "https://9to5linux.com/feed/", "hashtag": "#linux"},
    {"url": "https://www.gamingonlinux.com/article_rss.php", "hashtag": "#linux"},
    {"url": "https://itsfoss.com/feed/", "hashtag": "#linux"},
    {"url": "https://www.omgubuntu.co.uk/feed/", "hashtag": "#linux"},
    {"url": "https://rozetked.me/turbo", "hashtag": "#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏#–≥–∞–¥–∂–µ—Ç—ã#—Ç–µ—Ö–Ω–∏–∫–∞#–∞–≤—Ç–æ"},
    {"url": "https://mobile-review.com/all/news/feed/", "hashtag": "#android"},
    {"url": "https://droider.ru/feed", "hashtag": "#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏#–≥–∞–¥–∂–µ—Ç—ã#—Ç–µ—Ö–Ω–∏–∫–∞#–∞–≤—Ç–æ"},
    {"url": "https://www.comss.ru/linux.php", "hashtag": "#linux"},
]

def parse_feed(url):
    """–ü–∞—Ä—Å–∏—Ç RSS —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'application/rss+xml, application/xml, text/xml'
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        content = response.content

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º windows-1251 –≤ UTF-8 –¥–ª—è –Ω—É–∂–Ω—ã—Ö —Å–∞–π—Ç–æ–≤
        if any(site in url for site in ['4pda.to', 'ixbt.com']):
            try:
                content = content.decode('windows-1251').encode('utf-8')
            except:
                pass

        # –ü–∞—Ä—Å–∏–º —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫
        feed = feedparser.parse(content)

        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞, –Ω–æ –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏ - –≤—Å–µ —Ä–∞–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º
        if feed.bozo and feed.entries:
            print(f"   ‚ö†Ô∏è –ï—Å—Ç—å –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞, –Ω–æ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω—ã: {feed.bozo_exception}")
            return feed
        elif feed.entries:
            return feed
        else:
            print(f"   ‚ùå –ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –≤ —Ñ–∏–¥–µ")
            return feedparser.parse("")

    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")
        return feedparser.parse("")

def is_russian_text(text):
    if not text:
        return False
    cyrillic_count = sum(1 for char in text if '\u0400' <= char <= '\u04FF')
    total_letters = sum(1 for char in text if char.isalpha())
    return (cyrillic_count / total_letters) > 0.3 if total_letters >= 3 else False

def translate_text(text):
    try:
        if not text or not text.strip():
            return text
        url = "https://translate.googleapis.com/translate_a/single"
        params = {'client': 'gtx', 'sl': 'auto', 'tl': 'ru', 'dt': 't', 'q': text}
        response = requests.get(url, params=params, timeout=10)
        return response.json()[0][0][0] if response.status_code == 200 else text
    except Exception:
        return text

def prepare_news_content(title, description):
    was_translated = False
    processed_title = title

    if not is_russian_text(title):
        translated_title = translate_text(title)
        if translated_title and translated_title != title:
            processed_title = translated_title
            was_translated = True

    processed_description = ""
    if description:
        # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ HTML —Ç–µ–≥–æ–≤
        clean_desc = re.sub('<[^<]+?>', '', description)
        clean_desc = html.unescape(clean_desc)
        clean_desc = re.sub(r'\s+', ' ', clean_desc).strip()

        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—Å—Ç–∞—Ç–∫–∏ –±–∏—Ç—ã—Ö —Ç–µ–≥–æ–≤
        clean_desc = re.sub(r'<[^>]*$', '', clean_desc)  # —É–¥–∞–ª—è–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ —Ç–µ–≥–∏ –≤ –∫–æ–Ω—Ü–µ
        clean_desc = re.sub(r'^[^<]*>', '', clean_desc)  # —É–¥–∞–ª—è–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ —Ç–µ–≥–∏ –≤ –Ω–∞—á–∞–ª–µ

        if len(clean_desc) > 400:
            clean_desc = clean_desc[:400] + "..."
        if not is_russian_text(clean_desc) and clean_desc.strip():
            translated_desc = translate_text(clean_desc)
            if translated_desc and translated_desc != clean_desc:
                processed_description = translated_desc
                was_translated = True
            else:
                processed_description = clean_desc
        else:
            processed_description = clean_desc

    return processed_title, processed_description, was_translated

def extract_image_from_entry(entry):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ RSS –∑–∞–ø–∏—Å–∏"""
    try:
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–Ω—Ç
        if hasattr(entry, 'links'):
            for link in entry.links:
                if 'image' in link.type:
                    return link.href

        # 2. –ò—â–µ–º img —Ç–µ–≥–∏ –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ
        content_fields = ['summary', 'content', 'description']
        for field in content_fields:
            if hasattr(entry, field):
                content = getattr(entry, field)
                if isinstance(content, list):
                    content = content[0].value if content else ""
                img_match = re.search(r'<img[^>]+src="([^">]+)"', content)
                if img_match:
                    img_url = img_match.group(1)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫–∞—Ä—Ç–∏–Ω–∫–∞
                    if any(ext in img_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']):
                        return img_url

        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ–¥–∏–∞-thumbnail
        if hasattr(entry, 'media_thumbnail') and entry.media_thumbnail:
            return entry.media_thumbnail[0]['url']

        # 4. –î–ª—è Rozetked: –∏—â–µ–º –≤ enclosure
        if hasattr(entry, 'enclosures'):
            for enclosure in entry.enclosures:
                if 'image' in enclosure.type:
                    return enclosure.href

        # 5. –ò—â–µ–º –≤ content:encoded –µ—Å–ª–∏ –µ—Å—Ç—å
        if hasattr(entry, 'content_encoded'):
            img_match = re.search(r'<img[^>]+src="([^">]+)"', entry.content_encoded)
            if img_match:
                img_url = img_match.group(1)
                if any(ext in img_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']):
                    return img_url

    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")

    return None

def create_news_message(domain, title, description, link, pub_date, was_translated, hashtag):
    """–°–æ–∑–¥–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ —Å markdown —Ä–∞–∑–º–µ—Ç–∫–æ–π"""
    message_parts = [
        f"üåê {domain}",
        "",  # –ü—Ä–æ–±–µ–ª –ø–æ—Å–ª–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        f"üì¢ *{title}*",
    ]

    if description:
        message_parts.append("")  # –ü—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –æ–ø–∏—Å–∞–Ω–∏–µ–º
        message_parts.append(f"üìù **{description}**")

    message_parts.extend([
        "",  # –ü—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ —Å—Å—ã–ª–∫–æ–π
        f"üîó [–ß–∏—Ç–∞—Ç—å]({link})",
        "",  # –ü—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –¥–∞—Ç–æ–π
        f"üìÖ {pub_date}",
    ])

    if hashtag:
        message_parts.append("")  # –ü—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ —Ö—ç—à—Ç–µ–≥–æ–º
        message_parts.append(f"üè∑Ô∏è {hashtag}")

    if was_translated:
        message_parts.append("\n`üî§ [–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ]`")

    return "\n".join(message_parts)

def send_news_message(title, description, link, pub_date, image_url=None, was_translated=False, hashtag=""):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram"""
    try:
        domain = urlparse(link).netloc.replace('www.', '')
        message_text = create_news_message(domain, title, description, link, pub_date, was_translated, hashtag)

        if image_url:
            url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
            data = {
                'chat_id': TELEGRAM_CHANNEL_ID,
                'photo': image_url,
                'caption': message_text,
                'parse_mode': 'Markdown'
            }
        else:
            url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
            data = {
                'chat_id': TELEGRAM_CHANNEL_ID,
                'text': message_text,
                'parse_mode': 'Markdown'
            }

        response = requests.post(url, data=data, timeout=10)
        if response.status_code == 200:
            print(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {title[:50]}... {hashtag}")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {response.status_code}")
            return False

    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
        return False

def run_bot():
    last_links = {}
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    for source in RSS_SOURCES:
        url, hashtag = source["url"], source["hashtag"]
        try:
            feed = parse_feed(url)
            if feed.entries:
                last_links[url] = feed.entries[0].link
                print(f"‚úÖ {urlparse(url).netloc} {hashtag}")
            elif feed.bozo:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {feed.bozo_exception}")
        except Exception as e:
            print(f"üí• –û—à–∏–±–∫–∞ {url}: {e}")

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
    while True:
        try:
            print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞... ({datetime.now().strftime('%H:%M:%S')})")
            found_new_news = False

            for source in RSS_SOURCES:
                url, hashtag = source["url"], source["hashtag"]

                try:
                    feed = parse_feed(url)
                    if not feed.entries:
                        continue

                    latest, link = feed.entries[0], feed.entries[0].link

                    if url not in last_links or last_links[url] != link:
                        if url in last_links:
                            print(f"üéâ –ù–û–í–û–°–¢–¨: {hashtag}")
                            found_new_news = True

                        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                        pub_date = "–î–∞—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞"
                        if hasattr(latest, 'published_parsed') and latest.published_parsed:
                            pub_date = datetime(*latest.published_parsed[:6]).strftime("%d.%m.%Y %H:%M")

                        title, description, was_translated = prepare_news_content(
                            latest.title,
                            latest.description if hasattr(latest, 'description') else ""
                        )

                        image_url = extract_image_from_entry(latest)
                        if image_url:
                            print(f"   üñºÔ∏è –ù–∞–π–¥–µ–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏")
                        else:
                            print(f"   üìÑ –ö–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

                        # –û—Ç–ø—Ä–∞–≤–∫–∞
                        if send_news_message(title, description, link, pub_date, image_url, was_translated, hashtag):
                            last_links[url] = link

                except Exception as e:
                    print(f"üí• –û—à–∏–±–∫–∞ {url}: {e}")

            print(f"‚è∞ –û–∂–∏–¥–∞–Ω–∏–µ 15 –º–∏–Ω—É—Ç..." if not found_new_news else "‚úÖ –ù–æ–≤–æ—Å—Ç–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã")
            time.sleep(900)

        except Exception as e:
            print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            time.sleep(60)

@app.route('/')
def home():
    return "ü§ñ Telegram RSS Bot —Ä–∞–±–æ—Ç–∞–µ—Ç!"

@app.route('/ping')
def ping():
    return "pong"

bot_thread = threading.Thread(target=run_bot)
bot_thread.daemon = True
bot_thread.start()

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
