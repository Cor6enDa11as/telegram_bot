#!/usr/bin/env python3
import os
import feedparser
import requests
import certifi  # ‚Üê –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è SSL –Ω–∞ Render
from flask import Flask
from threading import Thread
import time
import logging
from dotenv import load_dotenv
import re
from urllib.parse import urljoin, urlparse

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

load_dotenv()
app = Flask(__name__)

BOT_TOKEN = os.getenv('BOT_TOKEN')
CHANNEL_ID = os.getenv('CHANNEL_ID')
RSS_FEED_URLS = [url.strip() for url in os.getenv('RSS_FEED_URLS', '').split(',') if url.strip()]

if not all([BOT_TOKEN, CHANNEL_ID, RSS_FEED_URLS]):
    logger.error("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
    exit(1)

last_links = {}

def extract_clean_text(html):
    if not html:
        return ""
    clean = re.sub(r'<[^>]+>', ' ', html)
    clean = re.sub(r'\s+', ' ', clean).strip()
    return clean[:300] + "‚Ä¶" if len(clean) > 300 else clean

def fetch_rss_with_browser_headers(rss_url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9,ru;q=0.8',
        'Connection': 'keep-alive',
    }
    response = requests.get(rss_url, headers=headers, timeout=20)
    response.raise_for_status()
    return feedparser.parse(response.content)

def robust_parse_feed(rss_url):
    methods = [
        lambda: fetch_rss_with_browser_headers(rss_url),
        lambda: feedparser.parse(rss_url),
    ]
    for method in methods:
        try:
            feed = method()
            if feed and hasattr(feed, 'entries') and len(feed.entries) > 0:
                entry = feed.entries[0]
                if entry.get('link') or entry.get('title'):
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {urlparse(rss_url).netloc}")
                    return feed
        except Exception as e:
            logger.debug(f"–ú–µ—Ç–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è {rss_url}: {e}")
            continue
    logger.error(f"‚ùå –í—Å–µ –º–µ—Ç–æ–¥—ã –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å: {rss_url}")
    return None

def get_news_image(entry, link, rss_url):
    # 1. media:content (4PDA, GSM Arena)
    try:
        if hasattr(entry, 'media_content') and entry.media_content:
            img = entry.media_content[0].get('url')
            if img and img.startswith(('http://', 'https://')):
                return img
    except: pass

    # 2. enclosures
    try:
        if hasattr(entry, 'enclosures') and entry.enclosures:
            for enc in entry.enclosures:
                url = getattr(enc, 'href', getattr(enc, 'url', None))
                if url and url.startswith(('http://', 'https://')):
                    return url
    except: pass

    # 3. og:image –∏–∑ HTML
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        resp = requests.get(link, headers=headers, timeout=10)
        if resp.ok:
            match = re.search(r'<meta[^>]*property=["\']og:image["\'][^>]*content=["\']([^"\']+)["\']', resp.text, re.I)
            if match:
                img_url = match.group(1)
                if img_url.startswith('/'):
                    img_url = urljoin(link, img_url)
                if img_url.startswith('http'):
                    return img_url
    except: pass

    # 4. fallback-–∏–∫–æ–Ω–∫–∏
    domain = urlparse(rss_url).netloc.replace('www.', '').split('.')[0].lower()
    fallbacks = {
        '4pda': 'https://i.imgur.com/rKzB0yP.png',
        'opennet': 'https://i.imgur.com/5XJmVQl.png',
        'gsmarena': 'https://i.imgur.com/9WzFQ4a.png',
        'ixbt': 'https://i.imgur.com/mVQkD3v.png',
        'habr': 'https://i.imgur.com/ZlZ3qDk.png',
        'default': 'https://i.imgur.com/3GtB4kP.png'
    }
    return fallbacks.get(domain, fallbacks['default'])

def send_via_telegraph(entry, rss_url):
    raw_title = entry.get('title', '–ù–æ–≤–æ—Å—Ç—å').strip()
    # –û—á–∏—Å—Ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    title = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', raw_title)
    title = re.sub(r'[|\\¬´¬ª‚Äú‚Äù\[\]]', '-', title)
    title = re.sub(r'-+', '-', title)
    title = re.sub(r'\s+', ' ', title).strip()
    if not title or len(title) < 2:
        title = "–ù–æ–≤–æ—Å—Ç—å"
    if len(title) > 240:
        title = title[:240].rsplit(' ', 1)[0] + "..."

    summary = extract_clean_text(entry.get('summary') or entry.get('description') or '')
    link = entry.get('link')
    if not link:
        logger.error("‚ùå –ù–µ—Ç —Å—Å—ã–ª–∫–∏ ‚Äî –ø—Ä–æ–ø—É—Å–∫")
        return False

    image_url = get_news_image(entry, link, rss_url)

    content = []
    if image_url:
        content.append({"tag": "img", "attrs": {"src": image_url}})
    if summary:
        content.append({"tag": "p", "children": [summary]})
    content.append({
        "tag": "p",
        "children": [
            {"tag": "em", "children": ["–ò—Å—Ç–æ—á–Ω–∏–∫: "]},
            {"tag": "a", "attrs": {"href": link}, "children": [link]}
        ]
    })

    payload = {
        "title": title,
        "author_name": "RSS Bot",
        "content": content,
        "return_content": False
    }

    try:
        # üîë –ö–ª—é—á–µ–≤–∞—è —Å—Ç—Ä–æ–∫–∞: certifi.where()
        resp = requests.post(
            "https://api.telegra.ph/createPage",
            json=payload,
            timeout=10,
            verify=certifi.where()
        )
        data = resp.json()
        if not resp.ok or not data.get("ok"):
            logger.error(f"‚ùå Telegraph –æ—à–∏–±–∫–∞: {data}")
            return False
        telegraph_url = data["result"]["url"]
    except Exception as e:
        logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ Telegraph: {e}")
        return False

    domain = urlparse(rss_url).netloc.replace('www.', '').split('.')[0].lower()
    hashtag = "#" + re.sub(r'[^a-zA-Z0-9–∞-—è–ê-–Ø—ë–Å]', '', domain)
    message = f"{telegraph_url}\n\n{title}\n\n{hashtag}"

    try:
        resp = requests.post(
            f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
            json={
                'chat_id': CHANNEL_ID,
                'text': message,
                'disable_web_page_preview': False
            },
            timeout=10
        )
        return resp.ok
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
        return False

def rss_check_loop():
    global last_links

    logger.info("üöÄ –ó–∞–ø—É—Å–∫ RSS –±–æ—Ç–∞ (Telegraph + Telegram preview)")

    for url in RSS_FEED_URLS:
        try:
            feed = robust_parse_feed(url)
            if feed and feed.entries:
                last_links[url] = feed.entries[0].link
                logger.info(f"‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {urlparse(url).netloc}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ {url}: {e}")

    time.sleep(60)

    while True:
        for url in RSS_FEED_URLS:
            try:
                # –í—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º GSM Arena –∏–∑-–∑–∞ 503
                if 'gsmarena.com' in url:
                    continue

                feed = robust_parse_feed(url)
                if not feed or not feed.entries:
                    continue

                latest = feed.entries[0]
                link = latest.link

                if last_links.get(url) != link:
                    logger.info(f"üéâ –ù–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å: {urlparse(url).netloc}")
                    if send_via_telegraph(latest, url):
                        last_links[url] = link
                        time.sleep(5)
                    else:
                        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å: {url}")

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {url}: {e}")

        logger.info("‚úÖ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à—ë–Ω")
        time.sleep(900)

@app.route('/')
def home():
    return 'RSS Bot ‚Äî Telegram Preview Mode (Telegraph + certifi)'

if __name__ == '__main__':
    logger.info(f"üì° –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è {len(RSS_FEED_URLS)} –ª–µ–Ω—Ç (GSM Arena –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á—ë–Ω)")
    Thread(target=rss_check_loop, daemon=True).start()
    app.run(host='0.0.0.0', port=int(os.getenv('PORT', 5000)))
