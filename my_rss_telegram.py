#!/usr/bin/env python3
import feedparser
import time
import requests
import re
import html
from datetime import datetime
import os

# =============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ò
# =============================================================================


TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHANNEL_ID = os.getenv('TELEGRAM_CHANNEL_ID')

RSS_SOURCES = [
    "https://habr.com/ru/rss/hubs/linux_dev/articles/?fl=ru",
    "https://habr.com/ru/rss/hubs/linux/articles/?fl=ru",
    "https://habr.com/ru/rss/hubs/popular_science/articles/?fl=ru",
    "https://habr.com/ru/rss/hubs/astronomy/articles/?fl=ru",
    "https://habr.com/ru/rss/hubs/futurenow/articles/?fl=ru",
    "https://habr.com/ru/rss/flows/popsci/articles/?fl=ru",
    "https://4pda.to/feed/",
    "https://tech.onliner.by/feed",
    "https://www.ixbt.com/export/hardnews.rss",
    "https://www.ixbt.com/export/sec_mobile.rss",
    "https://www.ixbt.com/export/sec_cpu.rss",
    "https://www.ixbt.com/export/applenews.rss",
    "https://www.ixbt.com/export/softnews.rss",
    "https://www.ixbt.com/export/sec_peripheral.rss",
    "http://androidinsider.ru/feed"
]

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –ü–ï–†–ï–í–û–î–ê
# =============================================================================

def is_russian_text(text):
    if not text:
        return False
    cyrillic_count = sum(1 for char in text if '\u0400' <= char <= '\u04FF')
    total_letters = sum(1 for char in text if char.isalpha())
    if total_letters < 3:
        return False
    return (cyrillic_count / total_letters) > 0.3

def translate_text(text):
    try:
        if not text or not text.strip():
            return text

        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            'client': 'gtx',
            'sl': 'auto',
            'tl': 'ru',
            'dt': 't',
            'q': text
        }

        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            return response.json()[0][0][0]
        return text
    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return text

def prepare_news_content(title, description):
    was_translated = False

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    processed_title = title
    if not is_russian_text(title):
        translated_title = translate_text(title)
        if translated_title and translated_title != title:
            processed_title = translated_title
            was_translated = True

    # –û–ø–∏—Å–∞–Ω–∏–µ
    processed_description = ""
    if description:
        clean_desc = re.sub('<[^<]+?>', '', description)
        clean_desc = html.unescape(clean_desc)
        clean_desc = re.sub(r'\s+', ' ', clean_desc).strip()

        if len(clean_desc) > 300:
            clean_desc = clean_desc[:300] + "..."

        if not is_russian_text(clean_desc) and clean_desc.strip():
            translated_desc = translate_text(clean_desc)
            if translated_desc and translated_desc != clean_desc:
                processed_description = translated_desc
                was_translated = True
            else:
                processed_description = clean_desc
        else:
            processed_description = clean_desc

    return processed_title, processed_description, was_translated

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ö–ê–†–¢–ò–ù–û–ö
# =============================================================================

def extract_image_from_entry(entry):
    try:
        if hasattr(entry, 'links'):
            for link in entry.links:
                if 'image' in link.type:
                    return link.href

        if hasattr(entry, 'summary'):
            img_match = re.search(r'<img[^>]+src="([^">]+)"', entry.summary)
            if img_match:
                return img_match.group(1)

        if hasattr(entry, 'media_thumbnail') and entry.media_thumbnail:
            return entry.media_thumbnail[0]['url']

    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")

    return None

# =============================================================================
# –§–£–ù–ö–¶–ò–Ø –û–¢–ü–†–ê–í–ö–ò –í TELEGRAM
# =============================================================================

def send_to_telegram(title, description, link, source_name, pub_date, image_url=None, was_translated=False):
    try:
        message = f"üì∞ **{source_name}**\n"
        message += f"üìÖ **{pub_date}**\n\n"

        if was_translated:
            message += "üî§ *[–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ]*\n\n"

        message += f"**{title}**\n\n"

        if description:
            message += f"{description}\n\n"

        message += f"üîó [–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é]({link})"

        if image_url:
            url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
            data = {
                'chat_id': TELEGRAM_CHANNEL_ID,
                'photo': image_url,
                'caption': message,
                'parse_mode': 'Markdown'
            }
        else:
            url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
            data = {
                'chat_id': TELEGRAM_CHANNEL_ID,
                'text': message,
                'parse_mode': 'Markdown',
                'disable_web_page_preview': False
            }

        response = requests.post(url, data=data, timeout=10)

        if response.status_code == 200:
            print(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {title[:50]}...")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: {response.status_code}")
            return False

    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
        return False

# =============================================================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø (–û–î–ù–ê –ü–†–û–í–ï–†–ö–ê)
# =============================================================================

def main():
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π...")
    print(f"üìä –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(RSS_SOURCES)}")

    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Å—ã–ª–æ–∫ (–≤ –ø–∞–º—è—Ç–∏)
    last_links = {}

    try:
        # –ß–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        try:
            with open('last_links.txt', 'r') as f:
                for line in f:
                    if ':' in line:
                        url, link = line.strip().split(':', 1)
                        last_links[url] = link
        except FileNotFoundError:
            print("üìù –§–∞–π–ª last_links.txt –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π...")

        new_links = {}

        for url in RSS_SOURCES:
            try:
                feed = feedparser.parse(url)
                if not feed.entries:
                    continue

                latest = feed.entries[0]
                link = latest.link

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –Ω–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å
                if url in last_links and last_links[url] == link:
                    continue

                print(f"üéâ –ù–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å: {feed.feed.title}")

                # –î–∞—Ç–∞
                if hasattr(latest, 'published_parsed') and latest.published_parsed:
                    pub_date = datetime(*latest.published_parsed[:6])
                    formatted_date = pub_date.strftime("%d.%m.%Y %H:%M")
                else:
                    formatted_date = "–î–∞—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞"

                # –ö–æ–Ω—Ç–µ–Ω—Ç —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º
                news_title = latest.title
                news_description = latest.description if hasattr(latest, 'description') else ""

                processed_title, processed_description, was_translated = prepare_news_content(
                    news_title, news_description
                )

                # –ö–∞—Ä—Ç–∏–Ω–∫–∞
                image_url = extract_image_from_entry(latest)

                # –ò—Å—Ç–æ—á–Ω–∏–∫
                source_name = feed.feed.title if hasattr(feed.feed, 'title') else url

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram
                send_to_telegram(
                    processed_title,
                    processed_description,
                    link,
                    source_name,
                    formatted_date,
                    image_url,
                    was_translated
                )

                new_links[url] = link
                time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–∞–º–∏

            except Exception as e:
                print(f"üí• –û—à–∏–±–∫–∞: {url} - {e}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏
        if new_links:
            with open('last_links.txt', 'w') as f:
                for url, link in new_links.items():
                    f.write(f"{url}:{link}\n")
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(new_links)} –Ω–æ–≤—ã—Ö —Å—Å—ã–ª–æ–∫")
        else:
            print("üì≠ –ù–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç")

    except Exception as e:
        print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()
