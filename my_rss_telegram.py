#!/usr/bin/env python3
import feedparser
import time
import requests
import re
import html
from datetime import datetime
import os
from flask import Flask
import threading
from urllib.parse import urlparse

app = Flask(__name__)

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHANNEL_ID = os.getenv('TELEGRAM_CHANNEL_ID')

if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHANNEL_ID:
    print("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã TELEGRAM_BOT_TOKEN –∏–ª–∏ TELEGRAM_CHANNEL_ID")
    exit(1)

RSS_SOURCES = [
    {"url": "https://habr.com/ru/rss/hubs/linux_dev/articles/?fl=ru", "hashtag": "#linux"},
    {"url": "https://habr.com/ru/rss/hubs/linux/articles/?fl=ru", "hashtag": "#linux"},
    {"url": "https://habr.com/ru/rss/hubs/popular_science/articles/?fl=ru", "hashtag": "#–Ω–∞—É–∫–∞"},
    {"url": "https://habr.com/ru/rss/hubs/astronomy/articles/?fl=ru", "hashtag": "#–∞—Å—Ç—Ä–æ–Ω–æ–º–∏—è"},
    {"url": "https://habr.com/ru/rss/flows/popsci/articles/?fl=ru", "hashtag": "#–Ω–∞—É–∫–∞"},
    {"url": "https://4pda.to/feed/", "hashtag": "#–º–æ–±–∏–ª—å–Ω—ã–µ"},
    {"url": "https://tech.onliner.by/feed", "hashtag": "#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"},
    {"url": "https://www.ixbt.com/export/news.rss", "hashtag": "#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"},
    {"url": "https://androidinsider.ru/feed", "hashtag": "#android"},
    {"url": "https://naked-science.ru/feed", "hashtag": "#–Ω–∞—É–∫–∞"},
    {"url": "https://www.opennet.ru/opennews/opennews_full_utf.rss", "hashtag": "#linux"},
    {"url": "https://www.comss.ru/linux.php", "hashtag": "#linux"},
    {"url": "https://www.linux.org.ru/section-rss.jsp?section=1", "hashtag": "#linux"},
    {"url": "https://www.phoronix.com/rss.php", "hashtag": "#linux"},
    {"url": "https://linuxiac.com/feed/", "hashtag": "#linux"},
    {"url": "https://www.linuxinsider.com/rss-feed", "hashtag": "#linux"},
    {"url": "https://distrowatch.com/news/dw.xml", "hashtag": "#linux"},
    {"url": "https://9to5linux.com/feed/", "hashtag": "#linux"},
    {"url": "https://www.gamingonlinux.com/article_rss.php", "hashtag": "#linux"},
    {"url": "https://itsfoss.com/feed/", "hashtag": "#linux"},
    {"url": "https://www.omgubuntu.co.uk/feed/", "hashtag": "#linux"},
    {"url": "https://rozetked.me/rss.xml", "hashtag": "#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"},
    {"url": "https://mobile-review.com/all/news/feed/", "hashtag": "#android"},
    {"url": "https://droider.ru/feed", "hashtag": "#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"},
    {"url": "https://www.comss.ru/linux.php", "hashtag": "#linux"},
]

def parse_feed(url):
    """–ü–∞—Ä—Å–∏—Ç RSS —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'application/rss+xml, application/xml, text/xml'
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        content = response.content

        if any(site in url for site in ['4pda.to', 'ixbt.com']):
            try:
                content = content.decode('windows-1251').encode('utf-8')
            except:
                pass

        feed = feedparser.parse(content)

        if feed.bozo and feed.entries:
            print(f"   ‚ö†Ô∏è –ï—Å—Ç—å –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞, –Ω–æ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω—ã: {feed.bozo_exception}")
            return feed
        elif feed.entries:
            return feed
        else:
            print(f"   ‚ùå –ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –≤ —Ñ–∏–¥–µ")
            return feedparser.parse("")

    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")
        return feedparser.parse("")

def is_russian_text(text):
    if not text:
        return False
    cyrillic_count = sum(1 for char in text if '\u0400' <= char <= '\u04FF')
    total_letters = sum(1 for char in text if char.isalpha())
    return (cyrillic_count / total_letters) > 0.3 if total_letters >= 3 else False

def translate_text(text):
    try:
        if not text or not text.strip():
            return text
        url = "https://translate.googleapis.com/translate_a/single"
        params = {'client': 'gtx', 'sl': 'auto', 'tl': 'ru', 'dt': 't', 'q': text}
        response = requests.get(url, params=params, timeout=10)
        return response.json()[0][0][0] if response.status_code == 200 else text
    except Exception:
        return text

def prepare_news_content(title, description):
    was_translated = False
    processed_title = title

    if not is_russian_text(title):
        translated_title = translate_text(title)
        if translated_title and translated_title != title:
            processed_title = translated_title
            was_translated = True

    processed_description = ""
    if description:
        clean_desc = re.sub('<[^<]+?>', '', description)
        clean_desc = html.unescape(clean_desc)
        clean_desc = re.sub(r'\s+', ' ', clean_desc).strip()
        clean_desc = re.sub(r'<[^>]*$', '', clean_desc)
        clean_desc = re.sub(r'^[^<]*>', '', clean_desc)

        if len(clean_desc) > 400:
            clean_desc = clean_desc[:400] + "..."
        if not is_russian_text(clean_desc) and clean_desc.strip():
            translated_desc = translate_text(clean_desc)
            if translated_desc and translated_desc != clean_desc:
                processed_description = translated_desc
                was_translated = True
            else:
                processed_description = clean_desc
        else:
            processed_description = clean_desc

    return processed_title, processed_description, was_translated

def extract_image_from_entry(entry):
    """–ü–æ–∏—Å–∫ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ RSS –∑–∞–ø–∏—Å–∏"""
    try:
        if hasattr(entry, 'links'):
            for link in entry.links:
                if 'image' in link.type:
                    return link.href
                if hasattr(link, 'rel') and 'enclosure' in link.rel:
                    if 'image' in getattr(link, 'type', ''):
                        return link.href

        if hasattr(entry, 'media_content'):
            for media in entry.media_content:
                if media.get('type', '').startswith('image/'):
                    return media['url']

        if hasattr(entry, 'media_thumbnail') and entry.media_thumbnail:
            return entry.media_thumbnail[0]['url']

        content_fields = ['summary', 'content', 'description', 'content_encoded']
        for field in content_fields:
            if hasattr(entry, field):
                content = getattr(entry, field)
                if isinstance(content, list):
                    content = content[0].value if content else ""
                if content:
                    img_match = re.search(r'<img[^>]+src="([^">]+)"', content)
                    if img_match:
                        img_url = img_match.group(1)
                        if any(ext in img_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']):
                            return img_url

        if hasattr(entry, 'enclosures'):
            for enclosure in entry.enclosures:
                if 'image' in getattr(enclosure, 'type', ''):
                    return enclosure.href

    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")

    return None

def check_site_supports_preview(link):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ —Å–∞–π—Ç Telegram –ø—Ä–µ–≤—å—é"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml'
        }

        response = requests.get(link, headers=headers, timeout=5)
        content = response.text

        has_og_image = 'property="og:image"' in content or 'property=\'og:image\'' in content
        has_og_title = 'property="og:title"' in content or 'property=\'og:title\'' in content
        has_twitter_image = 'name="twitter:image"' in content or 'name=\'twitter:image\'' in content

        supports_preview = has_og_image or has_twitter_image

        if supports_preview:
            print(f"   ‚úÖ –°–∞–π—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Ä–µ–≤—å—é (–Ω–∞–π–¥–µ–Ω—ã meta-—Ç–µ–≥–∏)")
        else:
            print(f"   ‚ùå –°–∞–π—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Ä–µ–≤—å—é (–Ω–µ—Ç meta-—Ç–µ–≥–æ–≤)")

        return supports_preview

    except Exception as e:
        print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–µ–≤—å—é: {e}")
        return False

def create_preview_message(link, pub_date, hashtag, was_translated):
    """–°–æ–∑–¥–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–≤—å—é —Å–æ —Å—Å—ã–ª–∫–æ–π"""
    message_parts = []

    # –î–ª—è –ø—Ä–µ–≤—å—é —Å—Å—ã–ª–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–º —ç–ª–µ–º–µ–Ω—Ç–æ–º
    message_parts.append(link)  # –ü—Ä–æ—Å—Ç–æ —Å—Å—ã–ª–∫–∞ –¥–ª—è –ø—Ä–µ–≤—å—é

    message_parts.extend([
        "",
        f"üìÖ {pub_date}",
        "",
    ])

    if hashtag:
        message_parts.append(f"üè∑Ô∏è {hashtag}")

    if was_translated:
        message_parts.append("")
        message_parts.append("üî§ [–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ]")

    return "\n".join(message_parts)

def create_full_message(domain, title, description, link, pub_date, was_translated, hashtag):
    """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π"""
    message_parts = [
        f"üåê {domain}",
        "",
        f"*{title}*",
    ]

    if description:
        message_parts.append("")
        message_parts.append(f"_{description}_")

    message_parts.extend([
        "",
        f"üîó {link}",  # –ü—Ä–æ—Å—Ç–æ —Å—Å—ã–ª–∫–∞
        "",
        f"üìÖ {pub_date}",
    ])

    if hashtag:
        message_parts.append("")
        message_parts.append(f"üè∑Ô∏è {hashtag}")

    if was_translated:
        message_parts.append("")
        message_parts.append("üî§ [–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ]")

    return "\n".join(message_parts)

def send_news_message(title, description, link, pub_date, image_url=None, was_translated=False, hashtag=""):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram"""
    try:
        domain = urlparse(link).netloc.replace('www.', '')

        # –£–ú–ù–ê–Ø –õ–û–ì–ò–ö–ê –í–´–ë–û–†–ê –§–û–†–ú–ê–¢–ê:
        supports_preview = check_site_supports_preview(link)

        if not was_translated and supports_preview:
            # Telegram –ø—Ä–µ–≤—å—é: —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π + –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Ä–µ–≤—å—é
            message_text = create_preview_message(link, pub_date, hashtag, was_translated)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–µ–∑ Markdown, —á—Ç–æ–±—ã —Å—Å—ã–ª–∫–∞ –±—ã–ª–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –¥–ª—è –ø—Ä–µ–≤—å—é
            url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
            data = {
                'chat_id': TELEGRAM_CHANNEL_ID,
                'text': message_text,
                'parse_mode': None,  # –ë–µ–∑ Markdown –¥–ª—è –ø—Ä–µ–≤—å—é
                'disable_web_page_preview': False  # –†–∞–∑—Ä–µ—à–∞–µ–º –ø—Ä–µ–≤—å—é
            }

            print(f"   üì± –ò—Å–ø–æ–ª—å–∑—É—é Telegram –ø—Ä–µ–≤—å—é")

        else:
            # –ü–æ–ª–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: –ª–∏–±–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–µ, –ª–∏–±–æ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Ä–µ–≤—å—é
            message_text = create_full_message(domain, title, description, link, pub_date, was_translated, hashtag)
            use_photo = bool(image_url)

            if use_photo and image_url:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π –∏–∑ RSS
                url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
                data = {
                    'chat_id': TELEGRAM_CHANNEL_ID,
                    'photo': image_url,
                    'caption': message_text,
                    'parse_mode': 'Markdown'
                }
            else:
                # –¢–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
                data = {
                    'chat_id': TELEGRAM_CHANNEL_ID,
                    'text': message_text,
                    'parse_mode': 'Markdown',
                    'disable_web_page_preview': True  # –ó–∞–ø—Ä–µ—â–∞–µ–º –ø—Ä–µ–≤—å—é
                }

            if was_translated:
                print(f"   üé® –ò—Å–ø–æ–ª—å–∑—É—é –ø–æ–ª–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–ø–µ—Ä–µ–≤–æ–¥)")
            else:
                print(f"   üé® –ò—Å–ø–æ–ª—å–∑—É—é –ø–æ–ª–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–Ω–µ—Ç –ø—Ä–µ–≤—å—é)")

        response = requests.post(url, data=data, timeout=10)

        if response.status_code == 200:
            print(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {title[:50]}... {hashtag}")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {response.status_code}")
            return False

    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
        return False

def run_bot():
    last_links = {}
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")

    for source in RSS_SOURCES:
        url, hashtag = source["url"], source["hashtag"]
        try:
            feed = parse_feed(url)
            if feed.entries:
                last_links[url] = feed.entries[0].link
                print(f"‚úÖ {urlparse(url).netloc} {hashtag}")
            elif feed.bozo:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {feed.bozo_exception}")
        except Exception as e:
            print(f"üí• –û—à–∏–±–∫–∞ {url}: {e}")

    while True:
        try:
            print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞... ({datetime.now().strftime('%H:%M:%S')})")
            found_new_news = False

            for source in RSS_SOURCES:
                url, hashtag = source["url"], source["hashtag"]

                try:
                    feed = parse_feed(url)
                    if not feed.entries:
                        continue

                    latest, link = feed.entries[0], feed.entries[0].link

                    if url not in last_links or last_links[url] != link:
                        if url in last_links:
                            print(f"üéâ –ù–û–í–û–°–¢–¨: {hashtag}")
                            found_new_news = True

                        pub_date = "–î–∞—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞"
                        if hasattr(latest, 'published_parsed') and latest.published_parsed:
                            pub_date = datetime(*latest.published_parsed[:6]).strftime("%d.%m.%Y %H:%M")

                        title, description, was_translated = prepare_news_content(
                            latest.title,
                            latest.description if hasattr(latest, 'description') else ""
                        )

                        image_url = extract_image_from_entry(latest)
                        if image_url:
                            print(f"   üñºÔ∏è –ù–∞–π–¥–µ–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∞ –≤ RSS")

                        if send_news_message(title, description, link, pub_date, image_url, was_translated, hashtag):
                            last_links[url] = link

                except Exception as e:
                    print(f"üí• –û—à–∏–±–∫–∞ {url}: {e}")

            print(f"‚è∞ –û–∂–∏–¥–∞–Ω–∏–µ 15 –º–∏–Ω—É—Ç..." if not found_new_news else "‚úÖ –ù–æ–≤–æ—Å—Ç–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã")
            time.sleep(900)

        except Exception as e:
            print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            time.sleep(60)

@app.route('/')
def home():
    return "ü§ñ Telegram RSS Bot —Ä–∞–±–æ—Ç–∞–µ—Ç!"

@app.route('/ping')
def ping():
    return "pong"

bot_thread = threading.Thread(target=run_bot)
bot_thread.daemon = True
bot_thread.start()

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
