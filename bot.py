#!/usr/bin/env python3
"""
üöÄ RSS to Telegram Bot (GitHub Actions) - –ü–û–õ–ù–ê–Ø –í–ï–†–°–ò–Ø –° –ü–û–ò–°–ö–û–ú –í –û–ü–ò–°–ê–ù–ò–ò
‚úÖ –§–ò–ö–° –¥—É–±–ª–µ–π + ‚úÖ –ü–û–õ–ù–´–ô –ø–æ–∏—Å–∫ –∫–∞—Ä—Ç–∏–Ω–æ–∫ (5 —ç—Ç–∞–ø–æ–≤)
"""

import os
import json
import feedparser
import requests
import time
import logging
import random
import re
from datetime import datetime, timezone, timedelta
from urllib.parse import urlparse

# ==================== –ù–ê–°–¢–†–û–ô–ö–ò ====================
BOT_TOKEN = os.getenv('BOT_TOKEN')
CHANNEL_ID = os.getenv('CHANNEL_ID')

if not BOT_TOKEN or not CHANNEL_ID:
    print("‚ùå –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ BOT_TOKEN –∏ CHANNEL_ID –≤ GitHub Secrets!")
    exit(1)

CONFIG = {
    'REQUEST_DELAY_MIN': int(os.getenv('REQUEST_DELAY_MIN', '5')),
    'REQUEST_DELAY_MAX': int(os.getenv('REQUEST_DELAY_MAX', '10')),
    'MAX_HOURS_BACK': int(os.getenv('MAX_HOURS_BACK', '24'))
}

RSS_FEEDS = []
HASHTAGS = {}

# ==================== –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ====================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_entry_image(entry):
    """üñºÔ∏è –≠—Ç–∞–ø—ã 1-4: enclosures ‚Üí media ‚Üí thumbnail ‚Üí image"""
    candidates = [
        getattr(entry, 'enclosures', [{}])[0].get('href') if entry.enclosures else None,
        getattr(entry, 'media_content', [{}])[0].get('url') if hasattr(entry, 'media_content') and entry.media_content else None,
        getattr(entry, 'media_thumbnail', [{}])[0].get('url') if hasattr(entry, 'media_thumbnail') and entry.media_thumbnail else None,
        getattr(entry, 'image', {}).get('href') if hasattr(entry, 'image') else None,
    ]
    for img_url in candidates:
        if img_url and (img_url.startswith('http') or img_url.startswith('//')):
            if img_url.startswith('//'):
                base_url = getattr(entry, 'base', 'https://example.com')
                if base_url.startswith('http'):
                    parsed = urlparse(base_url)
                    img_url = f"{parsed.scheme}:{img_url}"
            return img_url
    return None

def find_image_in_html(description):
    """üñºÔ∏è –≠—Ç–∞–ø 5: –ø–æ–∏—Å–∫ <img src=...> –≤ HTML –æ–ø–∏—Å–∞–Ω–∏–∏"""
    if not description:
        return None

    img_patterns = [
        r'<img[^>]+src="([^">]+)"',
        r"<img[^>]+src='([^'>]+)'",
        r'<img[^>]+src=([^\s>]+)'
    ]

    for pattern in img_patterns:
        match = re.search(pattern, description, re.IGNORECASE)
        if match:
            return match.group(1)
    return None

def clean_description(description):
    """üßπ –û—á–∏—â–∞–µ—Ç HTML, –æ–±—Ä–µ–∑–∞–µ—Ç –¥–æ 300 —Å–∏–º–≤–æ–ª–æ–≤"""
    if not description:
        return ''
    description = re.sub(r'<[^>]+>', '', description.strip())
    description = description.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
    return description[:300] + '...' if len(description) > 300 else description

def format_publication_date(pub_date):
    """üìÖ –§–æ—Ä–º–∞—Ç: 25.12.2025 14:30"""
    return pub_date.strftime('%d.%m.%Y %H:%M')

def send_to_telegram(title, link, feed_url, hashtags_dict, entry, pub_date):
    """üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç –° –ü–û–õ–ù–´–ú –ü–û–ò–°–ö–û–ú –ö–ê–†–¢–ò–ù–û–ö (5 —ç—Ç–∞–ø–æ–≤)"""
    try:
        clean_title = title.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        hashtag = hashtags_dict.get(feed_url, '#–Ω–æ–≤–æ—Å—Ç–∏')
        author = getattr(entry, 'author', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä').strip().replace(" ", "")

        original_description = getattr(entry, 'summary', '') or getattr(entry, 'description', '')
        description = clean_description(original_description)

        logger.info(f"  üìù –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞: {title[:50]}...")

        # üéØ –ü–û–õ–ù–´–ô –ü–û–ò–°–ö –ö–ê–†–¢–ò–ù–û–ö (5 —ç—Ç–∞–ø–æ–≤)
        image_url = None

        # –≠—Ç–∞–ø 1-4: RSS —Ç–µ–≥–∏
        image_url = get_entry_image(entry)
        if image_url:
            logger.info(f"  üñºÔ∏è –ù–∞–π–¥–µ–Ω–æ –≤ RSS: {image_url[:60]}...")

        # ‚úÖ –≠—Ç–∞–ø 5: HTML –æ–ø–∏—Å–∞–Ω–∏–µ (–í–û–ó–í–†–ê–©–Å–ù!)
        if not image_url and original_description:
            image_url = find_image_in_html(original_description)
            if image_url:
                logger.info(f"  üñºÔ∏è –ù–∞–π–¥–µ–Ω–æ –≤ HTML-–æ–ø–∏—Å–∞–Ω–∏–∏: {image_url[:60]}...")

        if not image_url:
            logger.info("  ‚ö†Ô∏è –ö–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        message_text = f'<a href="{link}">{clean_title}</a>'
        if description:
            message_text += f'\n\n<i>{description}</i>'
        message_text += f'\n\nüìå {hashtag} üë§ #{author}'

        # üì∏ –û–¢–ü–†–ê–í–ö–ê –° –ö–ê–†–¢–ò–ù–ö–û–ô (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1)
        if image_url:
            try:
                if image_url.startswith('//'):
                    image_url = 'https:' + image_url
                    logger.info(f"  üîó –§–∏–∫—Å URL: {image_url[:60]}...")

                logger.info(f"  üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ —Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π...")
                img_response = requests.get(image_url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})

                if img_response.status_code == 200:
                    photo_data = {
                        'chat_id': CHANNEL_ID,
                        'caption': message_text,
                        'parse_mode': 'HTML'
                    }
                    files = {'photo': ('image.jpg', img_response.content, img_response.headers.get('Content-Type', 'image/jpeg'))}

                    response = requests.post(
                        f'https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto',
                        files=files,
                        data=photo_data,
                        timeout=20
                    )

                    if response.status_code == 200:
                        logger.info("  ‚úÖ ‚úÖ –ü–æ—Å—Ç —Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω!")
                        time.sleep(random.uniform(1, 3))
                        return True
                    else:
                        logger.warning(f"  ‚ö†Ô∏è –§–æ—Ç–æ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {response.status_code}")

            except Exception as e:
                logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {str(e)[:80]}")

        # üìù –û–¢–ü–†–ê–í–ö–ê –¢–ï–ö–°–¢–û–ú (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2)
        logger.info("  üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–æ–º")
        data_text = {
            'chat_id': CHANNEL_ID,
            'text': message_text,
            'parse_mode': 'HTML',
            'disable_web_page_preview': 'true'
        }

        response = requests.post(
            f'https://api.telegram.org/bot{BOT_TOKEN}/sendMessage',
            data=data_text,
            timeout=10
        )

        if response.status_code == 200:
            logger.info("  ‚úÖ ‚úÖ –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω!")
            time.sleep(random.uniform(15, 25))
            return True
        else:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {response.status_code}")
            return False

    except Exception as e:
        logger.error(f"ü§ñ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return False

# ==================== –§–ê–ô–õ–´ ====================
def load_rss_feeds():
    """üìÅ feeds.txt: URL#—Ö—ç—à—Ç–µ–≥ –∏–ª–∏ URL ‚Üí #–Ω–æ–≤–æ—Å—Ç–∏"""
    global RSS_FEEDS, HASHTAGS
    try:
        with open('feeds.txt', 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                if '#' in line:
                    url, tag = line.split('#', 1)
                    RSS_FEEDS.append(url.strip())
                    HASHTAGS[url.strip()] = '#' + tag.strip()
                else:
                    RSS_FEEDS.append(line)
                    HASHTAGS[line] = '#–Ω–æ–≤–æ—Å—Ç–∏'
    except FileNotFoundError:
        logger.error("‚ùå feeds.txt –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        exit(1)

    if not RSS_FEEDS:
        logger.error("‚ùå –ù–µ—Ç RSS-–ª–µ–Ω—Ç!")
        exit(1)

    logger.info(f"üì∞ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(RSS_FEEDS)} –ª–µ–Ω—Ç")
    return RSS_FEEDS, HASHTAGS

def load_dates():
    """üìÖ dates.json ‚Üí datetime –æ–±—ä–µ–∫—Ç—ã"""
    try:
        with open('dates.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
            for url, info in data.items():
                if 'last_date' in info:
                    data[url]['last_date'] = datetime.fromisoformat(info['last_date'])
            return data
    except FileNotFoundError:
        return {}

def save_dates(dates_dict):
    """üíæ –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ last_date –∫–∞–∫ ISO —Å—Ç—Ä–æ–∫–∏"""
    data_to_save = {}
    for url, info in dates_dict.items():
        if isinstance(info, dict) and 'last_date' in info:
            data_to_save[url] = {'last_date': info['last_date'].isoformat()}

    with open('dates.json', 'w', encoding='utf-8') as f:
        json.dump(data_to_save, f, indent=2, ensure_ascii=False)

# ==================== RSS ====================
def parse_feed(url):
    """üåê –°–∫–∞—á–∏–≤–∞–µ—Ç RSS"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0', 'Accept': 'application/rss+xml'}
        response = requests.get(url, headers=headers, timeout=10)
        feed = feedparser.parse(response.content)
        return feed if hasattr(feed, 'entries') and feed.entries else None
    except Exception as e:
        logger.error(f"‚ùå –ü–∞—Ä—Å–∏–Ω–≥ {url[:40]}...: {e}")
        return None

def get_entry_date(entry):
    """üìÖ –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ UTC"""
    if hasattr(entry, 'published_parsed') and entry.published_parsed:
        return datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
    return datetime.now(timezone.utc)

# ==================== ‚úÖ –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê (–§–ò–ö–° –î–£–ë–õ–ï–ô) ====================
def check_feeds():
    """üîç –ü–†–û–í–ï–†–ö–ê –í–°–ï–• –õ–ï–ù–¢"""
    logger.info("=" * 60)
    logger.info(f"ü§ñ [{len(RSS_FEEDS)} –ª–µ–Ω—Ç] {datetime.now().strftime('%H:%M')}")
    start_time = time.time()

    dates = load_dates()
    sent_count = 0

    for feed_url in RSS_FEEDS:
        try:
            logger.info(f"üì∞ {feed_url[:50]}...")

            # ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –§–ò–ö–° –î–£–ë–õ–ï–ô!
            last_date = dates.get(feed_url, {}).get('last_date')
            if last_date is None:
                # üéØ –ü–ï–†–í–´–ô –ó–ê–ü–£–°–ö: —Ç–æ–ª—å–∫–æ 24—á –Ω–∞–∑–∞–¥
                threshold_date = datetime.now(timezone.utc) - timedelta(hours=24)
                logger.info("  üîÑ –ü–ï–†–í–´–ô –∑–∞–ø—É—Å–∫: –∑–∞ 24—á")
            else:
                # üéØ –î–ê–õ–¨–®–ï: —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –ø–æ—Å–ª–µ last_date
                threshold_date = last_date
                logger.info(f"  ‚è∞ –° last_date: {last_date.strftime('%H:%M')}")

            feed = parse_feed(feed_url)
            if not feed:
                time.sleep(random.uniform(CONFIG['REQUEST_DELAY_MIN'], CONFIG['REQUEST_DELAY_MAX']))
                continue

            new_entries = []
            for entry in feed.entries:
                entry_date = get_entry_date(entry)
                if entry_date > threshold_date:
                    new_entries.append((entry, entry_date))

            if new_entries:
                logger.info(f"  üì¶ –ù–æ–≤—ã—Ö: {len(new_entries)}")
                new_entries.sort(key=lambda x: x[1])  # –°—Ç–∞—Ä—ã–µ ‚Üí –Ω–æ–≤—ã–µ

                for entry, pub_date in new_entries:
                    title = getattr(entry, 'title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                    link = getattr(entry, 'link', '')
                    if not link:
                        continue

                    logger.info(f"  üì§ [{pub_date.strftime('%H:%M')}] {title[:60]}...")

                    if send_to_telegram(title, link, feed_url, HASHTAGS, entry, pub_date):
                        sent_count += 1
                        dates[feed_url] = {'last_date': pub_date}
                        save_dates(dates)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π!
                    else:
                        logger.error("  ‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏")
                        break
            else:
                logger.info("  ‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö")

            time.sleep(random.uniform(CONFIG['REQUEST_DELAY_MIN'], CONFIG['REQUEST_DELAY_MAX']))

        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
            continue

    save_dates(dates)  # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    logger.info(f"üìä –ì–û–¢–û–í–û! –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {sent_count}")
    logger.info(f"‚è±Ô∏è {time.time() - start_time:.1f}—Å")
    logger.info("=" * 60)
    return sent_count

# ==================== –ó–ê–ü–£–°–ö ====================
if __name__ == '__main__':
    logger.info("=" * 60)
    load_rss_feeds()
    logger.info(f"‚è∞ –ó–∞–¥–µ—Ä–∂–∫–∏: {CONFIG['REQUEST_DELAY_MIN']}-{CONFIG['REQUEST_DELAY_MAX']}—Å")
    logger.info("üÜï –õ–æ–≥–∏–∫–∞: 1–π –∑–∞–ø—É—Å–∫=24—á, –¥–∞–ª–µ–µ=—Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ")
    logger.info("üñºÔ∏è –ü–æ–∏—Å–∫ –∫–∞—Ä—Ç–∏–Ω–æ–∫: 5 —ç—Ç–∞–ø–æ–≤ (RSS + HTML)")
    logger.info("=" * 60)

    sent_count = check_feeds()
    logger.info(f"‚úÖ –ü–ï–†–§–ï–ö–¢! –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {sent_count} üöÄ")
